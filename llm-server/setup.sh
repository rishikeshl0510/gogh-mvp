#!/bin/bash

# Setup script for Gogh LLM Server

echo "ðŸš€ Setting up Gogh LLM Server..."

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama is not installed."
    echo "ðŸ“¥ Installing Ollama..."
    
    if [[ "$OSTYPE" == "darwin"* ]] || [[ "$OSTYPE" == "linux-gnu"* ]]; then
        curl -fsSL https://ollama.com/install.sh | sh
    else
        echo "âš ï¸  Please install Ollama manually from https://ollama.com"
        exit 1
    fi
fi

echo "âœ… Ollama is installed"

# Start Ollama service
echo "ðŸ”§ Starting Ollama service..."
ollama serve &
sleep 3

# Pull recommended model
echo "ðŸ“¦ Pulling llama3.2:1b model (this may take a few minutes)..."
ollama pull llama3.2:1b

# Install npm dependencies
echo "ðŸ“¦ Installing npm dependencies..."
npm install

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "ðŸ“ Creating .env file..."
    cat > .env << EOF
# LLM Server Configuration
LLM_PORT=3001
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:1b
EOF
    echo "âœ… Created .env file"
fi

echo ""
echo "âœ… Setup complete!"
echo ""
echo "To start the server, run:"
echo "  npm start"
echo ""
echo "For development with auto-reload:"
echo "  npm run dev"

